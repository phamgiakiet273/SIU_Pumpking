# file: context_extractor.py

import os
import dotenv
from utils.logger import get_logger

from engine.VLM_Extractor.llm_model.qwen3.qwen3 import QwenChatModel

dotenv.load_dotenv()
logger = get_logger()

PROMPT_PATH = os.getenv("SUMMURAY_PROMPT_PATH")
BASE_OUTPUT_CRAW_PATH = os.getenv("BASE_OUTPUT_CRAW_PATH")


class ContextExtractor:
    def __init__(self, model_object: QwenChatModel):
        """
        Args:
            base_dir (str): Th∆∞ m·ª•c ch·ª©a c√°c file output crawl.
            prompt_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file .txt ch·ª©a prompt template.
            model_object (QwenChatModel): ƒê·ªëi t∆∞·ª£ng model ƒë√£ ƒë∆∞·ª£c t·∫£i s·∫µn.
        """
        self.base_dir = BASE_OUTPUT_CRAW_PATH
        self.qwen = model_object

        try:
            with open(PROMPT_PATH, "r", encoding="utf-8") as f:
                self.prompt_template = f.read()
            logger.info(f"‚úÖ ƒê√£ t·∫£i prompt template t·ª´ '{PROMPT_PATH}'")
        except FileNotFoundError:
            logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file prompt t·∫°i: {PROMPT_PATH}")
            raise

    def _read_all_context(self) -> str:
        """ƒê·ªçc t·∫•t c·∫£ c√°c file output trong th∆∞ m·ª•c."""
        context_parts = []
        # Logic ƒë·ªçc file kh√¥ng thay ƒë·ªïi, v·∫´n duy·ªát qua c√°c th∆∞ m·ª•c con
        for root, _, files in os.walk(self.base_dir):
            for file in files:
                # ƒêi·ªÅu ki·ªán t√¨m file v·∫´n gi·ªØ nguy√™n
                if file.startswith("output_") and file.endswith(".txt"):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, "r", encoding="utf-8") as f:
                            content = f.read().strip()
                            if content:
                                context_parts.append(content)
                    except Exception as e:
                        logger.warning(f"Kh√¥ng th·ªÉ ƒë·ªçc {file_path}: {e}")
        return "\n\n".join(context_parts)

    def extract(self, context_text: str) -> str:
        """Gh√©p context, g·ª≠i Qwen ƒë·ªÉ tr√≠ch xu·∫•t v√† l∆∞u k·∫øt qu·∫£."""
        context_text = self._read_all_context()
        if not context_text:
            logger.error("‚ùå Kh√¥ng t√¨m th·∫•y context trong c√°c file output.")
            return None

        prompt = self.prompt_template.format(context_text=context_text)

        logger.info("üß† ƒêang g·ª≠i y√™u c·∫ßu tr√≠ch xu·∫•t th√¥ng tin ƒë·∫øn model...")
        thinking, response = self.qwen.generate_response(prompt)
        logger.debug("ü§î Thinking Content:\n" + thinking)

        if response:
            try:
                # T√¨m t√™n file duy nh·∫•t trong th∆∞ m·ª•c g·ªëc (base_dir)
                i = 1
                while True:
                    # T√™n file s·∫Ω l√† sum_1.txt, sum_2.txt,...
                    output_filename = f"sum_{i}.txt"
                    output_filepath = os.path.join(self.base_dir, output_filename)
                    if not os.path.exists(output_filepath):
                        break
                    i += 1

                # Ghi k·∫øt qu·∫£ t√≥m t·∫Øt v√†o file
                with open(output_filepath, "w", encoding="utf-8") as f:
                    f.write(response)
                logger.info(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ t√≥m t·∫Øt v√†o: '{output_filepath}'")

            except Exception as e:
                logger.error(f"‚ùå L·ªói khi ƒëang l∆∞u file t√≥m t·∫Øt: {e}")

        return response
