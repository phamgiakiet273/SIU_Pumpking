# file: caption.py

import json
import re
from pathlib import Path
from typing import List, Optional, Dict, Any
import os
import dotenv
import numpy as np
from PIL import Image

from utils.logger import get_logger

# >>> THAY ƒê·ªîI 1: Import l·ªõp Qwen25VL chung m√† b·∫°n ƒë√£ t·∫°o
from engine.VLM_Extractor.llm_model.qwen25vl.qwen25vl import Qwen25VL

# ==============================================================================
# INITIALIZATION
# ==============================================================================
logger = get_logger()
dotenv.load_dotenv()
PROMPT_CAPTION_PATH = os.getenv("PROMPT_CAPTION_PATH")

# ==============================================================================
# MAIN CLASS
# ==============================================================================


class EventLocalizer:
    """
    S·ª≠ d·ª•ng model Qwen2.5-VL ƒë·ªÉ x√°c ƒë·ªãnh v√† khoanh v√πng c√°c s·ª± ki·ªán trong m·ªôt
    ph√¢n c·∫£nh video (shot), d·ª±a tr√™n h√¨nh ·∫£nh v√† ng·ªØ c·∫£nh vƒÉn b·∫£n.
    L·ªõp n√†y g·ªçi ƒë·∫øn l·ªõp Qwen25VL chung ƒë·ªÉ th·ª±c hi·ªán suy lu·∫≠n.
    """

    def __init__(self):
        """
        Kh·ªüi t·∫°o EventLocalizer b·∫±ng c√°ch g·ªçi l·ªõp Qwen25VL chung.
        """
        logger.info("üöÄ [EventLocalizer] ƒêang kh·ªüi t·∫°o Qwen25VL d√πng chung...")
        # >>> THAY ƒê·ªîI 2: S·ª≠ d·ª•ng l·∫°i l·ªõp Qwen25VL c·ªßa b·∫°n.
        # To√†n b·ªô logic t·∫£i model ph·ª©c t·∫°p ƒë√£ ƒë∆∞·ª£c chuy·ªÉn v√†o ƒë√¢y.
        self.qwen_model = Qwen25VL()

        # T·∫£i prompt template nh∆∞ b√¨nh th∆∞·ªùng
        self.prompt_template = self._load_prompt_template(PROMPT_CAPTION_PATH)
        logger.info("‚úÖ [EventLocalizer] ƒê·ªëi t∆∞·ª£ng ƒë√£ s·∫µn s√†ng.")

    def _load_prompt_template(self, template_path: str) -> str:
        """T·∫£i n·ªôi dung prompt t·ª´ m·ªôt file text."""
        # ... (H√†m n√†y kh√¥ng thay ƒë·ªïi)
        if not template_path:
            raise ValueError("PROMPT_CAPTION_PATH ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p trong .env")
        path = Path(template_path)
        if not path.exists():
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file prompt t·∫°i '{template_path}'")
        with open(path, "r", encoding="utf-8") as f:
            return f.read()

    def _load_images(self, frame_paths: List[str]) -> Optional[List[np.ndarray]]:
        """T·∫£i ·∫£nh t·ª´ danh s√°ch ƒë∆∞·ªùng d·∫´n."""
        # ... (H√†m n√†y kh√¥ng thay ƒë·ªïi)
        images = []
        unique_paths = sorted(list(set(frame_paths)), key=frame_paths.index)
        for path_str in unique_paths:
            p = Path(path_str)  # Kh√¥ng c·∫ßn th√™m .jpg v√¨ ƒë∆∞·ªùng d·∫´n ƒë√£ ƒë·∫ßy ƒë·ªß
            if not p.exists():
                logger.warning(f"  [EventLocalizer] B·ªè qua frame kh√¥ng t·ªìn t·∫°i: {p}")
                continue
            try:
                with Image.open(p) as img:
                    images.append(np.array(img.convert("RGB")))
            except Exception as e:
                logger.warning(f"  [EventLocalizer] Kh√¥ng th·ªÉ m·ªü ·∫£nh {p}: {e}")
        return images if images else None

    def _build_prompt(self, s2t: str, context_text: str) -> str:
        """T·∫°o prompt chi ti·∫øt cho model."""
        # ... (H√†m n√†y kh√¥ng thay ƒë·ªïi)
        s2t_content = s2t if s2t else "Kh√¥ng c√≥ gi·ªçng n√≥i."
        context_content = (
            context_text
            if context_text
            else "Kh√¥ng c√≥ ng·ªØ c·∫£nh b·ªï sung, t·∫≠p trung v√†o c√°c khung h√¨nh trong video"
        )
        return self.prompt_template.format(
            s2t=s2t_content, context_text=context_content
        )

    def _parse_json_from_model_output(self, output_text: str) -> Optional[List[Dict]]:
        """Tr√≠ch xu·∫•t v√† parse kh·ªëi JSON t·ª´ output th√¥ c·ªßa model."""
        # ... (H√†m n√†y kh√¥ng thay ƒë·ªïi)
        json_pattern = re.search(
            r"```json\s*([\s\S]*?)\s*```|(\[[\s\S]*\]|{[\s\S]*})", output_text
        )
        if not json_pattern:
            logger.warning(
                "  [EventLocalizer] Kh√¥ng t√¨m th·∫•y kh·ªëi JSON trong output c·ªßa model."
            )
            return None
        json_str = json_pattern.group(1) or json_pattern.group(2)
        try:
            json_str_cleaned = json_str.strip().replace("'", '"')
            return json.loads(json_str_cleaned)
        except json.JSONDecodeError:
            logger.error(
                f"  [EventLocalizer] L·ªói khi parse JSON t·ª´ chu·ªói: {json_str[:200]}..."
            )
            return None

    def localize_events_in_shot(
        self, shot_data: Dict[str, Any], context_text: str
    ) -> Optional[Dict[str, Any]]:
        """
        Ph∆∞∆°ng th·ª©c ch√≠nh ƒë·ªÉ x·ª≠ l√Ω m·ªôt shot duy nh·∫•t, g·ªçi ƒë·∫øn l·ªõp Qwen25VL chung.
        """
        frames = shot_data.get("frames", [])
        if not frames:
            logger.warning("  [EventLocalizer] Shot kh√¥ng c√≥ danh s√°ch frames, b·ªè qua.")
            return None

        images = self._load_images(frames)
        if not images:
            logger.error(
                "  [EventLocalizer] Kh√¥ng th·ªÉ t·∫£i b·∫•t k·ª≥ frame n√†o, kh√¥ng th·ªÉ x·ª≠ l√Ω."
            )
            return None

        # Chu·∫©n b·ªã ƒë·∫ßu v√†o cho model
        video_data = np.stack(images)
        s2t = shot_data.get("s2t", "")
        prompt = self._build_prompt(s2t=s2t, context_text=context_text)

        # >>> THAY ƒê·ªîI 3: X√¢y d·ª±ng payload v√† g·ªçi h√†m `infer` c·ªßa l·ªõp chung
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "video", "video": video_data},
                    {"type": "text", "text": prompt},
                ],
            }
        ]

        logger.info(
            f"  [EventLocalizer] G·ª≠i y√™u c·∫ßu ({len(images)} frame) ƒë·∫øn l·ªõp Qwen25VL d√πng chung..."
        )
        raw_output_text = self.qwen_model.infer(messages)

        # X·ª≠ l√Ω output nh∆∞ c≈©
        parsed_json = self._parse_json_from_model_output(raw_output_text)

        return {
            "localized_events": parsed_json,
            "model_raw_output": raw_output_text,
            "context_provided": context_text,
        }
