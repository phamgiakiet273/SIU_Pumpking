# file: main.py
import os
import json
import logging
from title_extractor import TitleExtractor
from context_web import NewsPipeline
from context_extractor import ContextExtractor
from event_localizer import EventLocalizer


def setup_logging(log_dir):
    """C·∫•u h√¨nh logging."""
    os.makedirs(log_dir, exist_ok=True)
    log_file_path = os.path.join(log_dir, "pipeline_main.log")

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(log_file_path, mode="w", encoding="utf-8"),
            logging.StreamHandler(),
        ],
    )
    return log_file_path


def process_single_shot(
    shot_data,
    shot_index,
    config,
    title_extractor,
    context_extractor_model,
    event_localizer,
):
    """
    X·ª≠ l√Ω tr·ªçn v·∫πn m·ªôt shot duy nh·∫•t: t·ª´ tr√≠ch xu·∫•t ti√™u ƒë·ªÅ ƒë·∫øn khoanh v√πng s·ª± ki·ªán.
    C√°c module n·∫∑ng ƒë∆∞·ª£c truy·ªÅn v√†o ƒë·ªÉ tr√°nh t·∫£i l·∫°i model m·ªói l·∫ßn.
    """
    logging.info(f"{'='*25} B·∫ÆT ƒê·∫¶U X·ª¨ L√ù SHOT #{shot_index} {'='*25}")

    # ===== B∆Ø·ªöC 1: TR√çCH XU·∫§T TI√äU ƒê·ªÄ =====
    # L·∫•y 10 frame ƒë·∫ßu ƒë·ªÉ tr√≠ch xu·∫•t ti√™u ƒë·ªÅ
    frames_for_title = shot_data.get("frames", [])[:10]
    if not frames_for_title:
        logging.warning(
            f"Shot #{shot_index}: Kh√¥ng c√≥ frame ƒë·ªÉ tr√≠ch xu·∫•t ti√™u ƒë·ªÅ, b·ªè qua."
        )
        return None

    extracted_title = title_extractor.extract_title(frames_for_title)
    logging.info(f"Shot #{shot_index} - Ti√™u ƒë·ªÅ tr√≠ch xu·∫•t: {extracted_title}")

    # ===== B∆Ø·ªöC 2 & 3: CRAWL WEB V√Ä TR√çCH XU·∫§T NG·ªÆ C·∫¢NH RI√äNG =====
    context_text = "Kh√¥ng c√≥ ng·ªØ c·∫£nh b·ªï sung t·ª´ web."  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh
    if not extracted_title or extracted_title.startswith("L·ªói:"):
        logging.error(
            f"Shot #{shot_index}: Ti√™u ƒë·ªÅ kh√¥ng h·ª£p l·ªá, s·∫Ω ch·∫°y khoanh v√πng s·ª± ki·ªán kh√¥ng c√≥ ng·ªØ c·∫£nh web."
        )
    else:
        shot_output_dir = os.path.join(config["BASE_OUTPUT_CRAW_PATH"], "class_02")
        base_filename = os.path.basename(config["SHOT_JSON_PATH"])
        metadata_path = os.path.join(config["METADATA_BASE_PATH"], base_filename)

        # 2. Ch·∫°y pipeline crawl web cho ri√™ng shot n√†y
        web_pipeline = NewsPipeline(
            query=extracted_title,
            output_dir=shot_output_dir,
            metadata_path=metadata_path,
            shot_index=shot_index,
        )
        web_pipeline.run()

        # 3. Tr√≠ch xu·∫•t ng·ªØ c·∫£nh ch·ªâ t·ª´ th∆∞ m·ª•c c·ªßa shot n√†y
        # Ch√∫ √Ω: ContextExtractor gi·ªù ch·ªâ nh·∫≠n ƒë·∫ßu v√†o l√† shot_output_dir
        context_extractor = ContextExtractor(
            shot_output_dir, model_path=config["SUMMURAY_MODEL"]
        )
        shot_context = context_extractor.extract()

        if shot_context:
            context_text = shot_context
            logging.info(
                f"Shot #{shot_index} - Ng·ªØ c·∫£nh ri√™ng ƒë√£ tr√≠ch xu·∫•t th√†nh c√¥ng."
            )
            logging.debug(f"Shot #{shot_index} - N·ªôi dung ng·ªØ c·∫£nh:\n{context_text}")
        else:
            logging.warning(
                f"Shot #{shot_index}: Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c context t·ª´ web, d√π ƒë√£ crawl."
            )

    # ===== B∆Ø·ªöC 4: KHOANH V√ôNG S·ª∞ KI·ªÜN V·ªöI NG·ªÆ C·∫¢NH ƒê√öNG =====
    logging.info(
        f"Shot #{shot_index}: B·∫Øt ƒë·∫ßu khoanh v√πng s·ª± ki·ªán v·ªõi ng·ªØ c·∫£nh ƒë√£ x·ª≠ l√Ω."
    )
    # ƒêi·ªÅu ch·ªânh h√†m EventLocalizer.run ƒë·ªÉ n√≥ c√≥ th·ªÉ ch·ªâ x·ª≠ l√Ω m·ªôt shot
    # ·ªû ƒë√¢y ta s·∫Ω truy·ªÅn to√†n b·ªô d·ªØ li·ªáu c·ªßa shot v√†o thay v√¨ ch·ªâ index
    shot_localization_result = event_localizer.localize_events_in_shot(
        shot_data=shot_data, context_text=context_text, max_frames=26
    )

    # Th√™m th√¥ng tin index c·ªßa shot v√†o k·∫øt qu·∫£ ƒë·ªÉ ti·ªán theo d√µi
    if shot_localization_result:
        shot_localization_result["shot_index"] = shot_index

    logging.info(f"{'='*25} HO√ÄN T·∫§T X·ª¨ L√ù SHOT #{shot_index} {'='*25}\n")
    return shot_localization_result


def main():
    """
    H√†m ch√≠nh ƒëi·ªÅu ph·ªëi to√†n b·ªô pipeline.
    """
    config = {
        "LOCAL_MODEL_PATH": "/workspace/competitions/NCKH/An/Qwen2.5-VL-3B-Instruct",
        "SUMMURAY_MODEL": "Qwen/Qwen3-1.7B",
        "SHOT_JSON_PATH": "/workspace/nhihtc/perfect/AIC2025/shot/vlm/L01_V001.json",
        "METADATA_BASE_PATH": "/dataset/AIC2024/original_dataset/0/metadata/media-info",
        "BASE_OUTPUT_CRAW_PATH": "/workspace/competitions/AIC_2025/SIU_Pumpking/engine/VLMs/output_crawl",
        "FINAL_RESULTS_PATH": "/workspace/competitions/AIC_2025/SIU_Pumpking/engine/VLMs/event_localization_results_final.json",
    }
    setup_logging(config["BASE_OUTPUT_CRAW_PATH"])
    logging.info("üöÄ B·∫Øt ƒë·∫ßu pipeline x·ª≠ l√Ω t·ª´ng shot ƒë·ªôc l·∫≠p...")

    # ===== KH·ªûI T·∫†O C√ÅC MODEL L·ªöN M·ªòT L·∫¶N DUY NH·∫§T =====
    # ƒêi·ªÅu n√†y gi√∫p ti·∫øt ki·ªám th·ªùi gian v√† b·ªô nh·ªõ, kh√¥ng c·∫ßn t·∫£i l·∫°i model cho m·ªói shot
    try:
        title_extractor = TitleExtractor(model_path=config["LOCAL_MODEL_PATH"])
        # Kh√¥ng c·∫ßn kh·ªüi t·∫°o ContextExtractor ·ªü ƒë√¢y v√¨ n√≥ kh√¥ng t·∫£i model n·∫∑ng
        event_localizer = EventLocalizer(model_path=config["LOCAL_MODEL_PATH"])
        logging.info("‚úÖ T·∫•t c·∫£ c√°c model l·ªõn ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.")
    except Exception as e:
        logging.critical(f"‚ùå L·ªói nghi√™m tr·ªçng khi kh·ªüi t·∫°o model: {e}", exc_info=True)
        return

    # ===== ƒê·ªåC D·ªÆ LI·ªÜU SHOT =====
    try:
        with open(config["SHOT_JSON_PATH"], "r", encoding="utf-8") as f:
            all_shots_data = json.load(f)
    except Exception as e:
        logging.critical(f"‚ùå L·ªói nghi√™m tr·ªçng khi ƒë·ªçc file JSON ch√≠nh: {e}")
        return

    # ===== L·∫∂P QUA T·ª™NG SHOT V√Ä X·ª¨ L√ù ƒê·ªòC L·∫¨P =====
    final_results = []
    for i, shot_data in enumerate(all_shots_data):
        if shot_data.get("class") == 2:
            # Truy·ªÅn c√°c model ƒë√£ kh·ªüi t·∫°o v√†o h√†m x·ª≠ l√Ω
            result = process_single_shot(
                shot_data=shot_data,
                shot_index=i,
                config=config,
                title_extractor=title_extractor,
                context_extractor_model=config[
                    "SUMMURAY_MODEL"
                ],  # ch·ªâ truy·ªÅn ƒë∆∞·ªùng d·∫´n model
                event_localizer=event_localizer,
            )
            if result:
                final_results.append(result)

    # ===== L∆ØU K·∫æT QU·∫¢ CU·ªêI C√ôNG =====
    with open(config["FINAL_RESULTS_PATH"], "w", encoding="utf-8") as f:
        json.dump(final_results, f, ensure_ascii=False, indent=2)

    logging.info(
        f"‚úÖ‚úÖ‚úÖ Pipeline ho√†n t·∫•t. To√†n b·ªô {len(final_results)} shot ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω."
    )
    logging.info(f"K·∫øt qu·∫£ cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {config['FINAL_RESULTS_PATH']}")


if __name__ == "__main__":
    main()
